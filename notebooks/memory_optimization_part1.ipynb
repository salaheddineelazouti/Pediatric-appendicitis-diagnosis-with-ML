{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory Optimization for Pediatric Appendicitis Model\n",
    "\n",
    "This notebook focuses on analyzing and optimizing memory usage in the pediatric appendicitis diagnosis model. We'll explore various techniques to improve memory efficiency while maintaining model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import time\n",
    "from memory_profiler import profile, memory_usage\n",
    "import psutil\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import project modules\n",
    "from src.data_processing.preprocess import load_data, handle_missing_values, optimize_memory\n",
    "\n",
    "# Set plot styling\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('viridis')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['axes.titlesize'] = 18\n",
    "plt.rcParams['axes.labelsize'] = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Memory Profiling Functions\n",
    "\n",
    "Let's define some functions to help us measure and profile memory usage throughout our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size(obj, seen=None):\n",
    "    \"\"\"Recursively find the size of objects in bytes\"\"\"\n",
    "    size = sys.getsizeof(obj)\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "    obj_id = id(obj)\n",
    "    if obj_id in seen:\n",
    "        return 0\n",
    "    seen.add(obj_id)\n",
    "    if isinstance(obj, dict):\n",
    "        size += sum([get_size(v, seen) for v in obj.values()])\n",
    "        size += sum([get_size(k, seen) for k in obj.keys()])\n",
    "    elif hasattr(obj, '__dict__'):\n",
    "        size += get_size(obj.__dict__, seen)\n",
    "    elif hasattr(obj, '__iter__') and not isinstance(obj, (str, bytes, bytearray)):\n",
    "        size += sum([get_size(i, seen) for i in obj])\n",
    "    return size\n",
    "\n",
    "def memory_usage_dataframe(df):\n",
    "    \"\"\"Calculate DataFrame memory usage in MB\"\"\"\n",
    "    usage_bytes = df.memory_usage(deep=True).sum()\n",
    "    usage_mb = usage_bytes / (1024 * 1024)  # Convert to MB\n",
    "    return usage_mb\n",
    "\n",
    "def profile_function(func, *args, **kwargs):\n",
    "    \"\"\"Profile a function's memory usage and execution time\"\"\"\n",
    "    # Collect garbage before profiling\n",
    "    gc.collect()\n",
    "    \n",
    "    # Measure memory usage\n",
    "    mem_before = psutil.Process().memory_info().rss / (1024 * 1024)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Execute function\n",
    "    result = func(*args, **kwargs)\n",
    "    \n",
    "    # Measure final memory and time\n",
    "    end_time = time.time()\n",
    "    mem_after = psutil.Process().memory_info().rss / (1024 * 1024)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    execution_time = end_time - start_time\n",
    "    memory_used = mem_after - mem_before\n",
    "    \n",
    "    print(f\"Function: {func.__name__}\")\n",
    "    print(f\"Memory Usage: {memory_used:.2f} MB\")\n",
    "    print(f\"Execution Time: {execution_time:.2f} seconds\")\n",
    "    \n",
    "    return result, memory_used, execution_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Profiling Memory Usage\n",
    "\n",
    "Let's load our dataset and analyze its initial memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_path = '../DATA/synthetic_appendicitis_data.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "\n",
    "# Check initial memory usage\n",
    "initial_memory = memory_usage_dataframe(df)\n",
    "print(f\"Initial memory usage: {initial_memory:.2f} MB\")\n",
    "\n",
    "# Analyze memory usage by column\n",
    "print(\"\\nMemory usage by column:\")\n",
    "memory_by_column = df.memory_usage(deep=True) / (1024 * 1024)  # Convert to MB\n",
    "for col in memory_by_column.index:\n",
    "    print(f\"{col}: {memory_by_column[col]:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data types and basic statistics\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Display memory usage by data type\n",
    "print(\"\\nMemory usage by data type:\")\n",
    "memory_by_dtype = df.groupby(by=lambda dt: df[dt].dtype).sum() / (1024 * 1024)\n",
    "print(memory_by_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Memory Optimization\n",
    "\n",
    "Let's implement some basic memory optimization techniques, such as downcasting numerical data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_datatypes(df, verbose=True):\n",
    "    \"\"\"Optimize DataFrame data types to reduce memory usage\"\"\"\n",
    "    result = df.copy()\n",
    "    original_memory = memory_usage_dataframe(result)\n",
    "    \n",
    "    # Optimize integers\n",
    "    int_columns = result.select_dtypes(include=['int']).columns\n",
    "    for col in int_columns:\n",
    "        col_min = result[col].min()\n",
    "        col_max = result[col].max()\n",
    "        \n",
    "        # Find the appropriate int type\n",
    "        if col_min >= 0:\n",
    "            if col_max < 2**8:\n",
    "                result[col] = result[col].astype(np.uint8)\n",
    "            elif col_max < 2**16:\n",
    "                result[col] = result[col].astype(np.uint16)\n",
    "            elif col_max < 2**32:\n",
    "                result[col] = result[col].astype(np.uint32)\n",
    "        else:\n",
    "            if col_min > -2**7 and col_max < 2**7:\n",
    "                result[col] = result[col].astype(np.int8)\n",
    "            elif col_min > -2**15 and col_max < 2**15:\n",
    "                result[col] = result[col].astype(np.int16)\n",
    "            elif col_min > -2**31 and col_max < 2**31:\n",
    "                result[col] = result[col].astype(np.int32)\n",
    "    \n",
    "    # Optimize floats\n",
    "    float_columns = result.select_dtypes(include=['float']).columns\n",
    "    for col in float_columns:\n",
    "        result[col] = pd.to_numeric(result[col], downcast='float')\n",
    "    \n",
    "    # Optimize objects (strings)\n",
    "    categorical_threshold = 0.5  # Threshold for categorical conversion (50% unique values)\n",
    "    object_columns = result.select_dtypes(include=['object']).columns\n",
    "    for col in object_columns:\n",
    "        unique_count = len(result[col].unique())\n",
    "        total_count = len(result[col])\n",
    "        if unique_count / total_count < categorical_threshold:\n",
    "            result[col] = result[col].astype('category')\n",
    "    \n",
    "    # Calculate memory savings\n",
    "    optimized_memory = memory_usage_dataframe(result)\n",
    "    savings = original_memory - optimized_memory\n",
    "    savings_percent = (savings / original_memory) * 100\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Original memory usage: {original_memory:.2f} MB\")\n",
    "        print(f\"Optimized memory usage: {optimized_memory:.2f} MB\")\n",
    "        print(f\"Memory savings: {savings:.2f} MB ({savings_percent:.1f}%)\")\n",
    "    \n",
    "    return result, original_memory, optimized_memory, savings, savings_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply basic memory optimization\n",
    "df_optimized, orig_mem, opt_mem, savings, savings_pct = optimize_datatypes(df)\n",
    "\n",
    "# Compare data types before and after optimization\n",
    "print(\"\\nOriginal data types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\nOptimized data types:\")\n",
    "print(df_optimized.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot memory usage comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "memory_data = [orig_mem, opt_mem]\n",
    "labels = ['Original', 'Optimized']\n",
    "colors = ['#FF9999', '#66B2FF']\n",
    "\n",
    "bars = plt.bar(labels, memory_data, color=colors)\n",
    "plt.title('Memory Usage Comparison')\n",
    "plt.ylabel('Memory Usage (MB)')\n",
    "\n",
    "# Add data labels\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{height:.2f} MB', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Add savings annotation\n",
    "plt.annotate(f'Savings: {savings:.2f} MB ({savings_pct:.1f}%)',\n",
    "             xy=(1, opt_mem), xytext=(1.1, opt_mem + (orig_mem - opt_mem)/2),\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05, width=1.5, headwidth=8),\n",
    "             fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Enhanced Memory Optimization\n",
    "\n",
    "Let's implement additional techniques for memory optimization, focusing on feature selection and dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Prepare data for feature selection\n",
    "X = df_optimized[['Age', 'Temperature', 'WBC', 'CRP', 'Pain_Duration', 'Neutrophil_Percent']]\n",
    "y = df_optimized['Appendicitis']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Function to apply feature selection\n",
    "def apply_feature_selection(X_train, X_test, y_train, k=4):\n",
    "    \"\"\"Apply SelectKBest to select top k features\"\"\"\n",
    "    selector = SelectKBest(f_classif, k=k)\n",
    "    X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "    X_test_selected = selector.transform(X_test)\n",
    "    \n",
    "    # Get the names of selected features\n",
    "    selected_indices = selector.get_support(indices=True)\n",
    "    selected_features = X_train.columns[selected_indices]\n",
    "    \n",
    "    # Create DataFrames with selected features\n",
    "    X_train_df = pd.DataFrame(X_train_selected, columns=selected_features)\n",
    "    X_test_df = pd.DataFrame(X_test_selected, columns=selected_features)\n",
    "    \n",
    "    print(f\"Selected top {k} features: {', '.join(selected_features)}\")\n",
    "    return X_train_df, X_test_df, selected_features\n",
    "\n",
    "# Apply feature selection\n",
    "X_train_selected, X_test_selected, selected_features = apply_feature_selection(X_train, X_test, y_train, k=4)\n",
    "\n",
    "# Calculate memory savings\n",
    "original_X_train_memory = memory_usage_dataframe(pd.DataFrame(X_train))\n",
    "selected_X_train_memory = memory_usage_dataframe(X_train_selected)\n",
    "\n",
    "feature_selection_savings = original_X_train_memory - selected_X_train_memory\n",
    "feature_selection_savings_pct = (feature_selection_savings / original_X_train_memory) * 100\n",
    "\n",
    "print(f\"\\nMemory usage with all features: {original_X_train_memory:.4f} MB\")\n",
    "print(f\"Memory usage with selected features: {selected_X_train_memory:.4f} MB\")\n",
    "print(f\"Memory savings: {feature_selection_savings:.4f} MB ({feature_selection_savings_pct:.1f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
